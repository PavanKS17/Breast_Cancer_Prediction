{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bZun5kK8GFQh",
        "wBs3pqLHGFQs",
        "d4TSavm1GFQz",
        "MEfQFnRHGFQ_",
        "HWSXtjpDGFRR",
        "ihYDuBCNGFRU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5d2qLckGFQY"
      },
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chFsLeTrH7EF"
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pgRZRyEcPHi",
        "outputId": "3d6ecf43-aca7-42b5-9ebb-da9860218b4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTYVwVG73zJY"
      },
      "source": [
        "import pickle\n",
        "train_audio_emb, val_audio_emb, test_audio_emb = pickle.load(open(\"/gdrive/My Drive/Emotion detection/audio_embeddings_feature_selection_emotion.pkl\", 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSzmCFRG4BLI",
        "outputId": "8a9ba030-8956-474c-9f86-0a3053669366"
      },
      "source": [
        "len(train_audio_emb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9989"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v21d9Q9kNsZQ"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdOajIM5GFQa"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(\"train_sent_emo_1.csv\")\n",
        "#data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fiWqxhFpjZ_8",
        "outputId": "d287401c-3030-4783-a3f6-e4b1f81ae77a"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>also I was the point person on my companys tr...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You mustve had your hands full.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That I did. That I did.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So lets talk a little bit about your duties.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My duties?  All right.</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9984</th>\n",
              "      <td>You or me?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9985</th>\n",
              "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9986</th>\n",
              "      <td>You guys are messing with me, right?</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9987</th>\n",
              "      <td>Yeah.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>That was a good one. For a second there, I was...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9989 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotions\n",
              "0     also I was the point person on my companys tr...   neutral\n",
              "1                      You mustve had your hands full.   neutral\n",
              "2                               That I did. That I did.   neutral\n",
              "3         So lets talk a little bit about your duties.   neutral\n",
              "4                                My duties?  All right.  surprise\n",
              "...                                                 ...       ...\n",
              "9984                                         You or me?   neutral\n",
              "9985  I got it. Uh, Joey, women don't have Adam's ap...   neutral\n",
              "9986               You guys are messing with me, right?  surprise\n",
              "9987                                              Yeah.   neutral\n",
              "9988  That was a good one. For a second there, I was...       joy\n",
              "\n",
              "[9989 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7S3v9ooDbvV",
        "outputId": "ca15ae0b-df65-4f9f-ab86-58c25213e0e3"
      },
      "source": [
        "data_ind = data.index\n",
        "data_ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=9989, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QORvfWajJ9Ni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "069692ea-33ca-45f0-dabd-5fbf89ebad4a"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1315</th>\n",
              "      <td>Yeah, for you!</td>\n",
              "      <td>joy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9346</th>\n",
              "      <td>I mean doesn't she have any y'know other strip...</td>\n",
              "      <td>anger</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6624</th>\n",
              "      <td>I know!!   Chip? Hi! Its Monica.  Kay.  Kay...</td>\n",
              "      <td>joy</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5929</th>\n",
              "      <td>Yeah, thats what I drive. I make four bucks a...</td>\n",
              "      <td>disgust</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2986</th>\n",
              "      <td>Remember that guy from cooking school I told y...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7469</th>\n",
              "      <td>So I guess what I'm trying to say is that I'm ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>What?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8961</th>\n",
              "      <td>And you really think this is a good idea?</td>\n",
              "      <td>sadness</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8561</th>\n",
              "      <td>Okay. I went down to the Mattress King showr...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>What do you want from me, Ive never met the guy.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotions  token_size\n",
              "1315                                     Yeah, for you!       joy           3\n",
              "9346  I mean doesn't she have any y'know other strip...     anger          14\n",
              "6624  I know!!   Chip? Hi! Its Monica.  Kay.  Kay...       joy          24\n",
              "5929  Yeah, thats what I drive. I make four bucks a...   disgust          17\n",
              "2986  Remember that guy from cooking school I told y...   neutral          15\n",
              "...                                                 ...       ...         ...\n",
              "7469  So I guess what I'm trying to say is that I'm ...       joy          19\n",
              "192                                               What?   neutral           1\n",
              "8961          And you really think this is a good idea?   sadness           9\n",
              "8561  Okay. I went down to the Mattress King showr...   sadness          17\n",
              "3969  What do you want from me, Ive never met the guy.  surprise          11\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyAsI5Y5GFQd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "141e2ac2-a217-42be-c6a3-9da8f54aa14a"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1315</th>\n",
              "      <td>Yeah, for you!</td>\n",
              "      <td>joy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9346</th>\n",
              "      <td>I mean doesn't she have any y'know other strip...</td>\n",
              "      <td>anger</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6624</th>\n",
              "      <td>I know!!   Chip? Hi! Its Monica.  Kay.  Kay...</td>\n",
              "      <td>joy</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5929</th>\n",
              "      <td>Yeah, thats what I drive. I make four bucks a...</td>\n",
              "      <td>disgust</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2986</th>\n",
              "      <td>Remember that guy from cooking school I told y...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7469</th>\n",
              "      <td>So I guess what I'm trying to say is that I'm ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>What?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8961</th>\n",
              "      <td>And you really think this is a good idea?</td>\n",
              "      <td>sadness</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8561</th>\n",
              "      <td>Okay. I went down to the Mattress King showr...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>What do you want from me, Ive never met the guy.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotions  token_size\n",
              "1315                                     Yeah, for you!       joy           3\n",
              "9346  I mean doesn't she have any y'know other strip...     anger          14\n",
              "6624  I know!!   Chip? Hi! Its Monica.  Kay.  Kay...       joy          24\n",
              "5929  Yeah, thats what I drive. I make four bucks a...   disgust          17\n",
              "2986  Remember that guy from cooking school I told y...   neutral          15\n",
              "...                                                 ...       ...         ...\n",
              "7469  So I guess what I'm trying to say is that I'm ...       joy          19\n",
              "192                                               What?   neutral           1\n",
              "8961          And you really think this is a good idea?   sadness           9\n",
              "8561  Okay. I went down to the Mattress King showr...   sadness          17\n",
              "3969  What do you want from me, Ive never met the guy.  surprise          11\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZun5kK8GFQh"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7pp0WwkGFQj"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM_CVQCeGFQk"
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=9989);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI0wz10WGFQn"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm6T8QOKGFQo"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7jG2-EWGFQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd71381-a0cc-4811-f9a1-e41aee495eed"
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '!',\n",
              " '\"Benefits',\n",
              " '\"Big',\n",
              " '\"Blood\"',\n",
              " '\"Butternut',\n",
              " '\"Captain',\n",
              " '\"Circle',\n",
              " '\"Daddy,',\n",
              " '\"Days\"']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBs3pqLHGFQs"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaUZ6m_NGFQt"
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ_Rex25GFQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14c7ab9-812b-440d-cecc-232cc2083db9"
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2831,\n",
              "  4650,\n",
              "  6888,\n",
              "  8182,\n",
              "  5467,\n",
              "  8052,\n",
              "  5247,\n",
              "  8173,\n",
              "  3224,\n",
              "  7891,\n",
              "  3277,\n",
              "  10201,\n",
              "  5389,\n",
              "  8108,\n",
              "  3277,\n",
              "  3073,\n",
              "  10997,\n",
              "  11339,\n",
              "  6396,\n",
              "  6939,\n",
              "  7096,\n",
              "  8203,\n",
              "  3277,\n",
              "  9878,\n",
              "  7779,\n",
              "  6173,\n",
              "  3277,\n",
              "  10451,\n",
              "  7779,\n",
              "  7829],\n",
              " [2994, 8089]]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4TSavm1GFQz"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSf6c-QZGFQz"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htZ4w776GFQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237803af-9391-4fef-8fe8-c7474d686157"
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJvd2yKtGFQ5"
      },
      "source": [
        "# Padding the input and output tensor to the maximum length\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                             maxlen=max_length_inp,\n",
        "                                                             padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO6bbOOcGFQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c239e3c-f187-4d9c-ccc5-bdfc635c0357"
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2831,  4650,  6888,  8182,  5467,  8052,  5247,  8173,  3224,\n",
              "         7891,  3277, 10201,  5389,  8108,  3277,  3073, 10997, 11339,\n",
              "         6396,  6939,  7096,  8203,  3277,  9878,  7779,  6173,  3277,\n",
              "        10451,  7779,  7829,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0],\n",
              "       [ 2994,  8089,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeuWjKO2uCZX",
        "outputId": "8138a8b0-6e09-4a69-f910-4bc73dd91a12"
      },
      "source": [
        "print(input_tensor.shape)\n",
        "print(input_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9989, 69)\n",
            "[[ 2831  4650  6888 ...     0     0     0]\n",
            " [ 2994  8089     0 ...     0     0     0]\n",
            " [ 2629  7952 10541 ...     0     0     0]\n",
            " ...\n",
            " [  378  1308 11212 ...     0     0     0]\n",
            " [ 1954  3128  1308 ...     0     0     0]\n",
            " [ 1225 11337 10965 ...     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEfQFnRHGFQ_"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C2_dsoIGFRA"
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eGW9mBGGFRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79f05f8-d5b0-4c63-d6f1-e4fde6dc04e7"
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pQI0HFVGFRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f61b391-b165-47d8-d2ff-bf11e200ab99"
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2329</th>\n",
              "      <td>We couldnt keep our eyes off each other all n...</td>\n",
              "      <td>joy</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>Yeah, okay.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text emotions  token_size\n",
              "2329  We couldnt keep our eyes off each other all n...      joy          30\n",
              "1229                                        Yeah, okay.  neutral           2"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufoPZYHhDlvO",
        "outputId": "2f1e6a5d-7b0b-4578-c4b3-b9fe5b70a197"
      },
      "source": [
        "data.emotions.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joy', 'neutral', 'fear', 'surprise', 'anger', 'sadness',\n",
              "       'disgust'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlQcTB6RGFRH"
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQstuGUGFRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9cdb74-3e96-4ac9-fcb2-d4c79f6afd53"
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZrTGhU2GFRM"
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'disgust', 4: 'sadness', 5: 'surprise',6: 'neutral'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyOwWrguGFRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b029ba-8430-4fbd-d196-ded8d9644077"
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'disgust'"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWSXtjpDGFRR"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHRzfuFeGFRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8b94a5-9d09-4b7e-8e87-41519ae40eb1"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7991, 7991, 999, 999, 999, 999)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihYDuBCNGFRU"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also load the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In TensorFlow we can use the `tf.data` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jrchv51GFRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af55508-6166-4022-ff8e-070fbcddf80f"
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, \n",
        "                                                    target_tensor_train)).shuffle(TRAIN_BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, \n",
        "                                                  target_tensor_val)).shuffle(VAL_BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_test, \n",
        "                                                    target_tensor_test)).shuffle(TEST_BUFFER_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11400 256 1024 64 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH299tJOGFRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e046369-501e-43bf-ee0c-5bc299aa46c6"
      },
      "source": [
        "# checking minibatch\n",
        "print(train_dataset)\n",
        "print(val_dataset)\n",
        "print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((64, 69), (64, 7)), types: (tf.int32, tf.int64)>\n",
            "<BatchDataset shapes: ((64, 69), (64, 7)), types: (tf.int32, tf.int64)>\n",
            "<BatchDataset shapes: ((64, 69), (64, 7)), types: (tf.int32, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJUOo5xZGFRZ"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTaJh9SvGFRZ"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAzgaQGeGFRa"
      },
      "source": [
        "### define the GRU component\n",
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "  # the code automatically does that.\n",
        "    if tf.test.is_gpu_available():\n",
        "        return tf.compat.v1.keras.layers.CuDNNGRU(units, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True, \n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    else:\n",
        "        return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='relu', \n",
        "                               recurrent_initializer='glorot_uniform')\n",
        "\n",
        "### Build the model\n",
        "class EmoGRU(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "        self.gru = gru(self.hidden_units)\n",
        "        self.fc = tf.keras.layers.Dense(output_size)\n",
        "        \n",
        "    def call(self, x, hidden ):\n",
        "        x = self.embedding(x) # batch_size X max_len X embedding_dim\n",
        "        output, state = self.gru(x, initial_state = hidden) #  batch_size X max_len X hidden_units\n",
        "        out = output[:,-1,:]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out) # batch_size X max_len X output_size\n",
        "        return out, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.hidden_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkEFMmgvGFRc"
      },
      "source": [
        "### 4.1 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbgwa4AYGFRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28d7e00-0e2f-4ad5-b28a-09dd27257fbf"
      },
      "source": [
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# initialize the hidden state of the RNN\n",
        "hidden = model.initialize_hidden_state()\n",
        "\n",
        "# testing for the first batch only then break the for loop\n",
        "# Potential bug: out is not randomized enough\n",
        "for (batch, (inp, targ)) in enumerate(train_dataset):\n",
        "  print(inp.shape)\n",
        "  out, state = model(inp, hidden)\n",
        "  print(out.shape) \n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.EmoGRU object at 0x7fb03065a650>\n",
            "(64, 69)\n",
            "(64, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N75OFVzGFRf"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define our optimization algorithm, learning rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sakJKF51GFRj"
      },
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    return tf.compat.v1.losses.softmax_cross_entropy(y, logits=prediction)\n",
        "\n",
        "def accuracy(y, yhat):\n",
        "    #compare the predictions to the truth\n",
        "    yhat = tf.argmax(yhat, 1).numpy()\n",
        "    y    = tf.argmax(y   , 1).numpy()\n",
        "    return np.sum(y == yhat)/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CFw15JbGFRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "cf14e20f-6c4c-4c13-b36d-d0bba1d386f2"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    hidden = model.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions,_ = model(inp, hidden)\n",
        "            loss += loss_function(targ, predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        batch_accuracy = accuracy(targ, predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        gradients = tape.gradient(loss, model.variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    hidden = model.initialize_hidden_state()\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp, hidden)        \n",
        "        batch_accuracy = accuracy(targ, predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.2594\n",
            "Epoch 1 Batch 100 Val. Loss 0.2192\n",
            "Epoch 1 Loss 0.2220 -- Train Acc. 0.4704 -- Val Acc. 0.4760\n",
            "Time taken for 1 epoch 582.3811366558075 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.2227\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-129-ba714c867711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1744\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6015\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4pkIWl5GFRp"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LremGRu4GFRu"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmMrMca_GFRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061e886c-87d5-4cd3-960d-786676a35a42"
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "model.batch_sz = 64\n",
        "hidden = model.initialize_hidden_state()\n",
        "print(test_dataset)\n",
        "for (batch, (inp, targ)) in enumerate(test_dataset): \n",
        "  #print(batch , inp.shape  , targ.shape) \n",
        "  #print('inp:',inp)      \n",
        "  predictions,_ = model(inp, hidden)        \n",
        "  batch_accuracy = accuracy(targ, predictions)\n",
        "  test_accuracy += batch_accuracy\n",
        "  \n",
        "  x_raw = x_raw + [x for x in inp]\n",
        "  y_raw = y_raw + [y for y in targ]\n",
        "  \n",
        "  all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy/TEST_N_BATCH)\n",
        "print(len(all_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((64, 38), (64, 7)), types: (tf.int32, tf.int64)>\n",
            "Test Accuracy:  0.546875\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO-6bFGdvxuN",
        "outputId": "b33603d4-6de6-4782-e53a-a46b39181e96"
      },
      "source": [
        "print(np.array(x_raw).shape)\n",
        "print(np.array(y_raw).shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 38)\n",
            "(64, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-ZBUnuCEWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656190a4-97c4-4943-e7e6-0c3c1cc81c3a"
      },
      "source": [
        "!pip install ffmpeg moviepy\n",
        "import moviepy.editor as mp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.62.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=ba1e93f0f5b98320ddf89d327a358a792c1389b507c57d5bb04b4c561303b068\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3153920/45929032 bytes (6.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6823936/45929032 bytes (14.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10747904/45929032 bytes (23.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14737408/45929032 bytes (32.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18784256/45929032 bytes (40.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22716416/45929032 bytes (49.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26574848/45929032 bytes (57.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30220288/45929032 bytes (65.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34119680/45929032 bytes (74.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38109184/45929032 bytes (83.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42131456/45929032 bytes (91.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB5PVYdD6yYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5965493d-b27b-42b5-a7c7-b51bc48f8139"
      },
      "source": [
        "!pip install SpeechRecognition\n",
        "import os\n",
        "import speech_recognition as sr\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 33 kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYWOglaZCdJW"
      },
      "source": [
        "my_clip = mp.VideoFileClip(r\"testvideo.mp4\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NxKvBDYCpXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4eea7cf-20a5-42d6-a976-70f413ef8271"
      },
      "source": [
        "my_clip.audio.write_audiofile(r\"test_result.wav\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Writing audio in test_result.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10797/10797 [00:03<00:00, 2721.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH436iO9ETBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5824bcd4-bf4a-4e7e-c3fe-7ab45447fa41"
      },
      "source": [
        "converted_wav = 'test_result.wav'\n",
        "os.system(converted_wav)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08GV6_85Doyp"
      },
      "source": [
        "r = sr.Recognizer()\n",
        "audio = sr.AudioFile(\"test_result.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj0mI04mF9ok"
      },
      "source": [
        "with audio as source:\n",
        "  audio = r.record(source, duration=200)\n",
        "  output_string = r.recognize_google(audio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WORmWVRXjQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "87f6897c-08a5-4645-e679-cce9de47390a"
      },
      "source": [
        "output_string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"welcome to speak English with Tiffany I am teacher Tiffany and today I am going to teach you exactly how to give a five-minute speech and English this lesson will help you speak English more confidently in front of people are you ready to learn how well then let's Jump Right In giving a speech is not easy especially when it is an English but there are four easy steps that can help you give an amazing speech in English let's begin Step 1 the attention grabber the attention grabber is the starting point of every speech it is the step where we get grab and hold the attention of the audience there are three types of attention Grabbers the first one is is a story for this one you start off by telling a short story that connects to your speech and is also engaging the second one is an interesting fact for this one you want to tell and intriguing fact that directly relates to your topic and the third one is a question-and-answer time for this one your goal is to ask thought-provoking question that your audience will have to actually respond to this will get them engaged with you from the beginning so for example if our speech was about Oprah Winfrey and her success the three attention-grabbers would be set up like this remember this section only last for 1 minute for the story you can give us a story about the success of Oprah Winfrey one of the most successful women in the entire world by giving the story behind her success you will have the attention of your audience from the very beginning of your speech for the interesting fact you can give facts about the number of successful women there are in the world who are mothers and finally for the question-and-answer time you can think of two to three questions to ask the audience about their definition of success and also who is the most successful woman they know next step to the introduction the introduction is the transition section that leads directly into the topic of your speech this step is simple but very important there are three types of introductions the first one is General details for this one you simply give basic information about the topic the second one is three main points for this one you state the three\""
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhDc5qHZDoUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f188f44-d331-4eaa-9ba0-54c064feed1b"
      },
      "source": [
        "n = 15\n",
        "\n",
        "def group_words(s, n):\n",
        "    words = s.split()\n",
        "    for i in range(0, len(words), n):\n",
        "        yield ' '.join(words[i:i+n])\n",
        "\n",
        "out_list = list(group_words(output_string,n))\n",
        "out_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['welcome to speak English with Tiffany I am teacher Tiffany and today I am going',\n",
              " 'to teach you exactly how to give a five-minute speech and English this lesson will',\n",
              " 'help you speak English more confidently in front of people are you ready to learn',\n",
              " \"how well then let's Jump Right In giving a speech is not easy especially when\",\n",
              " 'it is an English but there are four easy steps that can help you give',\n",
              " \"an amazing speech in English let's begin Step 1 the attention grabber the attention grabber\",\n",
              " 'is the starting point of every speech it is the step where we get grab',\n",
              " 'and hold the attention of the audience there are three types of attention Grabbers the',\n",
              " 'first one is is a story for this one you start off by telling a',\n",
              " 'short story that connects to your speech and is also engaging the second one is',\n",
              " 'an interesting fact for this one you want to tell and intriguing fact that directly',\n",
              " 'relates to your topic and the third one is a question-and-answer time for this one',\n",
              " 'your goal is to ask thought-provoking question that your audience will have to actually respond',\n",
              " 'to this will get them engaged with you from the beginning so for example if',\n",
              " 'our speech was about Oprah Winfrey and her success the three attention-grabbers would be set',\n",
              " 'up like this remember this section only last for 1 minute for the story you',\n",
              " 'can give us a story about the success of Oprah Winfrey one of the most',\n",
              " 'successful women in the entire world by giving the story behind her success you will',\n",
              " 'have the attention of your audience from the very beginning of your speech for the',\n",
              " 'interesting fact you can give facts about the number of successful women there are in',\n",
              " 'the world who are mothers and finally for the question-and-answer time you can think of',\n",
              " 'two to three questions to ask the audience about their definition of success and also',\n",
              " 'who is the most successful woman they know next step to the introduction the introduction',\n",
              " 'is the transition section that leads directly into the topic of your speech this step',\n",
              " 'is simple but very important there are three types of introductions the first one is',\n",
              " 'General details for this one you simply give basic information about the topic the second',\n",
              " 'one is three main points for this one you state the three']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVEoWJP6fXsx",
        "outputId": "6ab5a170-7166-484f-85e0-279c4ea0c589"
      },
      "source": [
        "out_data = pd.DataFrame(out_list , columns = ['text'])\n",
        "out_data['token_size'] = out_data['text'].apply(lambda x: len(x.split(' ')))\n",
        "out_data = out_data.loc[out_data['token_size'] < 70].copy()\n",
        "print(out_data)\n",
        "\n",
        "inputs = ConstructVocab(out_data[\"text\"].values.tolist())\n",
        "print(inputs)\n",
        "# examples of what is in the vocab\n",
        "print(inputs.vocab[0:10])\n",
        "\n",
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in out_data[\"text\"].values.tolist()]\n",
        "print(input_tensor)\n",
        "\n",
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)\n",
        "\n",
        "# Padding the input and output tensor to the maximum length\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, maxlen=max_length_inp,padding='post')\n",
        "\n",
        "print(input_tensor.shape)\n",
        "#input_tensor = tf.convert_to_tensor(input_tensor, dtype=None, dtype_hint=None, name=None)\n",
        "#print(input_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 text  token_size\n",
            "0   welcome to speak English with Tiffany I am tea...          15\n",
            "1   to teach you exactly how to give a five-minute...          15\n",
            "2   help you speak English more confidently in fro...          15\n",
            "3   how well then let's Jump Right In giving a spe...          15\n",
            "4   it is an English but there are four easy steps...          15\n",
            "5   an amazing speech in English let's begin Step ...          15\n",
            "6   is the starting point of every speech it is th...          15\n",
            "7   and hold the attention of the audience there a...          15\n",
            "8   first one is is a story for this one you start...          15\n",
            "9   short story that connects to your speech and i...          15\n",
            "10  an interesting fact for this one you want to t...          15\n",
            "11  relates to your topic and the third one is a q...          15\n",
            "12  your goal is to ask thought-provoking question...          15\n",
            "13  to this will get them engaged with you from th...          15\n",
            "14  our speech was about Oprah Winfrey and her suc...          15\n",
            "15  up like this remember this section only last f...          15\n",
            "16  can give us a story about the success of Oprah...          15\n",
            "17  successful women in the entire world by giving...          15\n",
            "18  have the attention of your audience from the v...          15\n",
            "19  interesting fact you can give facts about the ...          15\n",
            "20  the world who are mothers and finally for the ...          15\n",
            "21  two to three questions to ask the audience abo...          15\n",
            "22  who is the most successful woman they know nex...          15\n",
            "23  is the transition section that leads directly ...          15\n",
            "24  is simple but very important there are three t...          15\n",
            "25  General details for this one you simply give b...          15\n",
            "26  one is three main points for this one you stat...          12\n",
            "<__main__.ConstructVocab object at 0x7f2a500ea350>\n",
            "['1', 'English', 'General', 'Grabbers', 'I', 'In', 'Jump', 'Oprah', 'Right', 'Step']\n",
            "[[155, 143, 116, 2, 161, 11, 5, 17, 127, 11, 20, 144, 5, 17, 60], [143, 126, 166, 45, 67, 143, 57, 13, 51, 117, 20, 2, 139, 83, 160], [64, 166, 116, 2, 88, 34, 70, 55, 94, 99, 21, 166, 105, 143, 82], [67, 156, 134, 84, 7, 9, 6, 58, 13, 117, 77, 92, 39, 43, 157], [78, 77, 19, 2, 31, 135, 21, 53, 39, 122, 130, 33, 64, 166, 57], [19, 18, 117, 70, 2, 84, 28, 10, 1, 131, 23, 62, 131, 23, 62], [77, 131, 119, 100, 94, 44, 117, 78, 77, 131, 121, 158, 154, 56, 61], [20, 66, 131, 23, 94, 131, 25, 135, 21, 141, 148, 94, 23, 4, 131], [50, 96, 77, 77, 13, 123, 52, 139, 96, 166, 118, 95, 32, 129, 13], [112, 123, 130, 35, 143, 167, 117, 20, 77, 16, 41, 131, 109, 96, 77], [19, 72, 47, 52, 139, 96, 166, 152, 143, 128, 20, 74, 47, 130, 38], [106, 143, 167, 145, 20, 131, 138, 96, 77, 13, 103, 142, 52, 139, 96], [167, 59, 77, 143, 22, 140, 102, 130, 167, 25, 160, 63, 143, 15, 108], [143, 139, 160, 56, 133, 40, 161, 166, 54, 131, 29, 115, 52, 46, 68], [98, 117, 153, 14, 8, 12, 20, 65, 124, 131, 141, 24, 165, 27, 111], [149, 85, 139, 107, 139, 110, 97, 80, 52, 1, 87, 52, 131, 123, 166], [33, 57, 150, 13, 123, 14, 131, 124, 94, 8, 12, 96, 94, 131, 89], [125, 163, 70, 131, 42, 164, 32, 58, 131, 123, 30, 65, 124, 166, 160], [63, 131, 23, 94, 167, 25, 54, 131, 151, 29, 94, 167, 117, 52, 131], [72, 47, 166, 33, 57, 48, 14, 131, 93, 94, 125, 163, 135, 21, 70], [131, 164, 159, 21, 90, 20, 49, 52, 131, 103, 142, 166, 33, 137, 94], [147, 143, 141, 104, 143, 22, 131, 25, 14, 132, 36, 94, 124, 20, 16], [159, 77, 131, 89, 125, 162, 136, 79, 91, 121, 143, 131, 75, 131, 75], [77, 131, 146, 110, 130, 81, 38, 73, 131, 145, 94, 167, 117, 139, 121], [77, 113, 31, 151, 69, 135, 21, 141, 148, 94, 76, 131, 50, 96, 77], [3, 37, 52, 139, 96, 166, 114, 57, 26, 71, 14, 131, 145, 131, 109], [96, 77, 141, 86, 101, 52, 139, 96, 166, 120, 131, 141]]\n",
            "15\n",
            "(27, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfBrzQbXodW8",
        "outputId": "71a88e1b-2a1e-48d8-9677-b559118b456a"
      },
      "source": [
        "#print(dir(model))\n",
        "test_new_pred1 = []\n",
        "model.batch_sz = 1\n",
        "hidden = model.initialize_hidden_state()\n",
        "print(input_tensor.shape)\n",
        "\n",
        "for inp in input_tensor :\n",
        "  #print(inp.shape)\n",
        "  inp = np.reshape(inp , (1,inp.shape[0]))\n",
        "  inp = tf.convert_to_tensor(inp,dtype=None, dtype_hint=None, name=None)\n",
        "  pred,_ = model(inp , hidden)\n",
        "  #print(pred.shape)\n",
        "  pred = pred[0].numpy()\n",
        "  #print(pred)\n",
        "  test_new_pred1.append(pred)\n",
        "\n",
        "test_new_pred1[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 4.1617355 , -1.9440538 , -2.26865   , -0.51516885,  5.2207503 ,\n",
              "        -6.524542  ], dtype=float32),\n",
              " array([ 1.2273123 ,  1.562949  ,  0.7866119 ,  1.5913186 ,  6.113726  ,\n",
              "        -0.82308304], dtype=float32),\n",
              " array([ 1.5132926, -6.7257605,  6.974586 ,  1.2493888,  4.527441 ,\n",
              "        -6.7480464], dtype=float32),\n",
              " array([ 7.7808867 , -0.64428836,  5.3262653 , -4.068712  ,  4.639493  ,\n",
              "        -7.63592   ], dtype=float32),\n",
              " array([-1.4907353, -2.6419609, 10.600937 ,  0.5117225,  5.833318 ,\n",
              "        -1.7351737], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7d1-JAYmDO4N",
        "outputId": "629eafd6-a50d-400a-9b80-036954335a55"
      },
      "source": [
        "data.iloc[data.index[0]]['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i wonder if im being at all realistic here because i feel like when i get fond of someone i typically view them in a somewhat idealized way'"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA5PESBKD6Oz"
      },
      "source": [
        "##check this\n",
        "def get_emotion1(pred):\n",
        "  dif = abs(pred - np.ones(6))\n",
        "  print(dif)\n",
        "  em = np.argmin(dif)\n",
        "  return em"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEwGEFO8AP6",
        "outputId": "e1d4facb-7274-4153-a8e5-f8093b3dfe84"
      },
      "source": [
        "motion_pred = []\n",
        "for i in range(0, len(test_new_pred1)):\n",
        "  pred = test_new_pred1[i]\n",
        "  em = get_emotion(pred)  #get_emotion1(pred)\n",
        "  em = emotion_dict[em]\n",
        "  txt = out_data.iloc[i]['text']\n",
        "  print(txt , '------>' , em)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "welcome to speak English with Tiffany I am teacher Tiffany and today I am going ------> sadness\n",
            "to teach you exactly how to give a five-minute speech and English this lesson will ------> sadness\n",
            "help you speak English more confidently in front of people are you ready to learn ------> joy\n",
            "how well then let's Jump Right In giving a speech is not easy especially when ------> anger\n",
            "it is an English but there are four easy steps that can help you give ------> joy\n",
            "an amazing speech in English let's begin Step 1 the attention grabber the attention grabber ------> anger\n",
            "is the starting point of every speech it is the step where we get grab ------> anger\n",
            "and hold the attention of the audience there are three types of attention Grabbers the ------> anger\n",
            "first one is is a story for this one you start off by telling a ------> fear\n",
            "short story that connects to your speech and is also engaging the second one is ------> surprise\n",
            "an interesting fact for this one you want to tell and intriguing fact that directly ------> sadness\n",
            "relates to your topic and the third one is a question-and-answer time for this one ------> sadness\n",
            "your goal is to ask thought-provoking question that your audience will have to actually respond ------> joy\n",
            "to this will get them engaged with you from the beginning so for example if ------> fear\n",
            "our speech was about Oprah Winfrey and her success the three attention-grabbers would be set ------> anger\n",
            "up like this remember this section only last for 1 minute for the story you ------> sadness\n",
            "can give us a story about the success of Oprah Winfrey one of the most ------> joy\n",
            "successful women in the entire world by giving the story behind her success you will ------> joy\n",
            "have the attention of your audience from the very beginning of your speech for the ------> anger\n",
            "interesting fact you can give facts about the number of successful women there are in ------> love\n",
            "the world who are mothers and finally for the question-and-answer time you can think of ------> fear\n",
            "two to three questions to ask the audience about their definition of success and also ------> joy\n",
            "who is the most successful woman they know next step to the introduction the introduction ------> joy\n",
            "is the transition section that leads directly into the topic of your speech this step ------> love\n",
            "is simple but very important there are three types of introductions the first one is ------> joy\n",
            "General details for this one you simply give basic information about the topic the second ------> surprise\n",
            "one is three main points for this one you state the three ------> anger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfumoK1A91e2"
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY3WyPnGiRxM",
        "outputId": "3f751ec1-c8eb-4e46-95f9-70adaee6a3cc"
      },
      "source": [
        "hidden"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "tFuzcc1MhWNG",
        "outputId": "f2d2f4cb-0ba6-4ffb-caff-8c9ef6b3f942"
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17734</th>\n",
              "      <td>i cannot help saying that i feel you are less ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87897</th>\n",
              "      <td>i havent been this weight in years and im feel...</td>\n",
              "      <td>joy</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions  token_size\n",
              "17734  i cannot help saying that i feel you are less ...      joy          21\n",
              "87897  i havent been this weight in years and im feel...      joy          12"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQElybUXGFRw"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNrZnOVyKyov"
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdJrBJxYGFRx"
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p)\n",
        "\n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict =  {0: 'anger', 1: 'fear', 2: 'joy', 3: 'disgust', 4: 'sadness', 5: 'surprise',6: 'neutral'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbjzYzJ2rpPt"
      },
      "source": [
        "We should input the real time streaming transcription model here that can be applied to live streams. For e.g: youtube.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzCiYOGyr8tb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "05f7bb74-8ffb-47a3-e090-9ae37df85e9b"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     emotion\n",
              "0   surprise\n",
              "1    sadness\n",
              "2    sadness\n",
              "3    disgust\n",
              "4      anger\n",
              "..       ...\n",
              "59   disgust\n",
              "60   sadness\n",
              "61     anger\n",
              "62   sadness\n",
              "63   sadness\n",
              "\n",
              "[64 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ]
}